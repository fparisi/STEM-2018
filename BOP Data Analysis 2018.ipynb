{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018 = pd.read_csv('C:\\\\Users\\\\Francis\\\\Google Drive\\\\Data\\\\___PACE\\\\STEM-Summer2018\\\\2018expeditions.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first five rows\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the column names\n",
    "data2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the last five rows\n",
    "data2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the data -- interchange rows and columns\n",
    "data2018 = data2018.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column names to the names in the first row  instead of 1, 2, ... \n",
    "data2018.columns = data2018.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the first row of the transposed data contains the variable names and not data, drop the first row\n",
    "data2018 = data2018.drop(data2018.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look and make sure you got what you wanted\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can print all the variable names\n",
    "for i in range(len(data2018.columns)):\n",
    "    print(data2018.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can explore specific subsets of the data\n",
    "# \"Oil sheen present? (1=Yes,0=No)\" is the second column so we can extract it via implicit indexing\n",
    "# Remember  Python indexing is zero based\n",
    "for i in range(3):\n",
    "    print(data2018.iloc[i, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the measuremts for all substrates for the second expedition\n",
    "data2018.iloc[1][\"Measurements (mm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can select multiple columns by using an array as the index\n",
    "data2018[[\"Measurements (mm)\", \"Total number of all live oysters\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values for each substrate shell for one expedition\n",
    "# Recall the expeditions are the rows so we use .iloc to pass the index location (row number)\n",
    "# This will create an array of strings, each string contains the measurements\n",
    "# vals is of type numpy.ndarray, and each element of vals is a str\n",
    "vals = data2018.iloc[0][\"Measurements (mm)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the dtype for vals\n",
    "type(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the dtype for the first element of vals\n",
    "# We see vals is a list of strings\n",
    "type(vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals # we see a mix of str and nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vals[0].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't do analysis yet because this is a list of str \n",
    "# We break out the individual values for the first strings but each is still a str\n",
    "# And we have to deal with nan \n",
    "# If we try to split() a nan we get an error\n",
    "vals[0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This throws an error because vals[1] is nan and nan's are floats not str\n",
    "vals[1].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series and DataFrames can use the dropna() method to remove nan's\n",
    "pd.Series(vals).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And to_numeric() converts strings to floats\n",
    "pd.to_numeric(pd.Series(vals[0].split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range(len(vals)):  # let's walk through the string array \n",
    "    if type(vals[v]) == str: # if the type is str then we can split() and make it a float\n",
    "        print(pd.to_numeric(pd.Series(vals).dropna()[v].split(\",\")))\n",
    "        # we can also print the mean for each substrate\n",
    "        print('Substrate Shell #' + str(v+1) + \": \\t The mean is \", \n",
    "              '%.3f' % pd.to_numeric(pd.Series(vals).dropna()[v].split(\",\")).mean(), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the column name to a simple variable rather than retype this whole thing\n",
    "wc = 'Water color\\r\\n(1=Light Blue,2=Dark Blue,3=Light Green,\\r\\n4=Dark Green,5=Light Brown,6=Dark Brown)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This stacks the measurements based on water color\n",
    "v1 = np.array([])\n",
    "v2 = np.array([])\n",
    "v3 = np.array([])\n",
    "v4 = np.array([])\n",
    "v5 = np.array([])\n",
    "v6 = np.array([])\n",
    "for l in range(len(data2018[\"Measurements (mm)\"].values)):\n",
    "    # temp stores the observations for one expedition\n",
    "    for t in range(10):\n",
    "        if pd.notnull(data2018.iloc[l]['Measurements (mm)'].values[t]):\n",
    "            w = np.array(data2018.iloc[l][\"Measurements (mm)\"].values[t].split(\",\")).astype(float)\n",
    "            if data2018.iloc[l][wc] == '1':\n",
    "                v1 = np.append(v1, w)\n",
    "            elif data2018.iloc[l][wc] == '2':\n",
    "                v2 = np.append(v2, w)\n",
    "            elif data2018.iloc[l][wc] == '3':\n",
    "                v3 = np.append(v3, w)\n",
    "            elif data2018.iloc[l][wc] == '4':\n",
    "                v4 = np.append(v4, w)\n",
    "            elif data2018.iloc[l][wc] == '5':\n",
    "                v5 = np.append(v5, w)\n",
    "            else:\n",
    "                v6 = np.append(v6, w)\n",
    "        else:\n",
    "            next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the measurements with water color into a new data frame\n",
    "measures = np.concatenate((v1, v2, v3, v4, v5, v6), axis=0)\n",
    "measures = pd.DataFrame({'Measures': measures})\n",
    "\n",
    "measures['WaterColor'] = np.zeros(len(measures['Measures']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.array([len(v1), len(v2), len(v3), len(v4),len(v5),len(v6)])\n",
    "ind\n",
    "\n",
    "cumind = np.cumsum(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cumind[0]):\n",
    "    measures.loc[i, 'WaterColor'] = 1\n",
    "for j in range(5):\n",
    "    for i in range(cumind[j],cumind[j+1]):\n",
    "        measures.loc[i, 'WaterColor'] = j+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some measurements are 99999 to indicate missing values! WHY???!!!\n",
    "# So get rid of them; measures has all the data excluding those observations where 'Measures' is 99999\n",
    "measures = measures[measures['Measures']!= 99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean for each color\n",
    "measures.groupby('WaterColor').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.groupby('WaterColor').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures['Measures'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.groupby('WaterColor').mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.groupby('WaterColor').size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, I made up a second variable to plot against my measurements data\n",
    "# I added random normal fluctuations to the measurements data (i.e., random noise)\n",
    "measures['Measures + Noise'] = measures['Measures'] + np.random.normal(0,4,627)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.plot.scatter(y = 'Measures + Noise', x = 'Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures['Measures'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = np.array([[np.random.normal(0,1,100)],[np.random.normal(0.5,0.8,100)]])\n",
    "plt.scatter(rn[0], rn[1])\n",
    "plt.title('Zero Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.normal(0,1,100)\n",
    "rn = np.array([w,w+2*np.random.normal(0,0.1,100)])\n",
    "plt.scatter(rn[0], rn[1])\n",
    "plt.title('Positive Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.normal(0,1,100)\n",
    "rn = np.array([w, -w+3*np.random.normal(0.5,0.1,100)])\n",
    "plt.scatter(rn[0], rn[1])\n",
    "plt.title('Negative Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures['Measures'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(measures['Measures'], measures['Measures + Noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The p-value near zero indicates the correlation is statistically significant\n",
    "rho, pstat = scipy.stats.pearsonr(measures['Measures'], measures['Measures + Noise'])\n",
    "print('rho = %.4f' % rho, 'p-val = %.4f' % pstat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're testing the hypothesis that the two sample means are equal (statistically speaking)\n",
    "tstat, pval = scipy.stats.ttest_ind(measures['Measures'], measures['Measures + Noise'])\n",
    "print('t-stat = %.3f ' % tstat, 'p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the mean measurements in two water colors are the same --- they're not; low p-value\n",
    "tstat, pval = scipy.stats.ttest_ind(v1, v5)\n",
    "print('t-stat = %.3f ' % tstat, 'p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to test if there is a difference in the means from multiple groups\n",
    "# use Analysis of Variance(ANOVA) \n",
    "fstat, pval = stats.f_oneway(v1, v3, v4, v5, v6)\n",
    "print('ANOVA Results', 'fstat = %.3f' % fstat, 'p-value = %.3f' % pval, '\\n', sep='\\t')\n",
    "\n",
    "# The null nypothesis for ANOVA is all means are equal\n",
    "# If your test suggests rejecting the null you need to do a Tukey HSD comparison\n",
    "# to see which pairs of means are different\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "print(pairwise_tukeyhsd(measures['Measures'], measures['WaterColor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the pH data issue for out of bounds data -- pH ranges from 0 to 14 \n",
    "# note the original list is a list of star coming out of the BOP data\n",
    "phs = pd.Series(['17.6', '8.2', '7.5'])\n",
    "phsf = phs.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsf[phsf > 14.0] = np.nan\n",
    "phsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
